{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-probability\n",
      "  Downloading tensorflow_probability-0.24.0-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: absl-py in /rsrch8/home/genetics/tchu/myenv/lib/python3.11/site-packages (from tensorflow-probability) (2.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /rsrch8/home/genetics/tchu/myenv/lib/python3.11/site-packages (from tensorflow-probability) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /rsrch8/home/genetics/tchu/myenv/lib/python3.11/site-packages (from tensorflow-probability) (1.26.4)\n",
      "Requirement already satisfied: decorator in /rsrch8/home/genetics/tchu/myenv/lib/python3.11/site-packages (from tensorflow-probability) (5.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /rsrch8/home/genetics/tchu/myenv/lib/python3.11/site-packages (from tensorflow-probability) (3.1.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in /rsrch8/home/genetics/tchu/myenv/lib/python3.11/site-packages (from tensorflow-probability) (0.6.0)\n",
      "Collecting dm-tree (from tensorflow-probability)\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Downloading tensorflow_probability-0.24.0-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "Installing collected packages: dm-tree, tensorflow-probability\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtfp\u001b[49m\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mBinomial(total_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, probs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mprob(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfp' is not defined"
     ]
    }
   ],
   "source": [
    "tfp.distributions.Binomial(total_count=2, probs=1 - 0.5).prob(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_probabilities_tf(C_TR, C_TA, C_NR, C_NA, major, minor, totalCN, TiN):\n",
    "    C_T = C_TA + C_TR\n",
    "    C_N = C_NA + C_NR\n",
    "    C = C_T + C_N\n",
    "    C_A = C_TA + C_NA\n",
    "    \n",
    "    if C == 0:\n",
    "        return tf.constant(0.0, dtype=tf.float32)\n",
    "\n",
    "    # Calculate likelihoods\n",
    "    P_R_no_mutation = tfp.distributions.Binomial(total_count=C, probs=1 - TNR).prob(C_A)\n",
    "    P_R_homozygous = tfp.distributions.Binomial(total_count=C, probs=TPR).prob(C_A)\n",
    "    P_R_heterozygous = tfp.distributions.Binomial(total_count=C, probs=(TPR + (1 - TNR)) / 2).prob(C_A)\n",
    "    P_R_clonal = tf.zeros_like(C_A, dtype=tf.float32)\n",
    "\n",
    "    # Check for totalCN = 0\n",
    "    if totalCN == 0:\n",
    "        P_R_clonal = tfp.distributions.Binomial(total_count=C, probs=1 - TNR).prob(C_A)\n",
    "    else:\n",
    "        VAF_values = tf.range(minor, major + 1, dtype=tf.float32) / totalCN\n",
    "        \n",
    "        # Use vectorized operations\n",
    "        tumor_prob = TiT * (VAF_values[:, tf.newaxis] * TPR + (1 - VAF_values[:, tf.newaxis]) * (1 - TNR)) + (1 - TiT) * (1 - TNR)\n",
    "        normal_prob = TiN * (VAF_values[:, tf.newaxis] * TPR + (1 - VAF_values[:, tf.newaxis]) * (1 - TNR)) + (1 - TiN) * (1 - TNR)\n",
    "\n",
    "        tumor_result = tfp.distributions.Binomial(total_count=C_T, probs=tumor_prob).prob(C_TA)\n",
    "        normal_result = tfp.distributions.Binomial(total_count=C_N, probs=normal_prob).prob(C_NA)\n",
    "\n",
    "        # Average over VAF values\n",
    "        P_R_clonal = tf.reduce_mean(tumor_result * normal_result, axis=0)\n",
    "\n",
    "    # Combine the probabilities\n",
    "    P_R = (P_R_no_mutation * p_no_mutation + \n",
    "            P_R_homozygous * p_homozygous + \n",
    "            P_R_heterozygous * p_heterozygous + \n",
    "            P_R_clonal * p_clonal)\n",
    "\n",
    "    return -tf.math.log(P_R)\n",
    "\n",
    "def total_log_likelihood(TiN, dataset):\n",
    "    total_log_likelihood = tf.constant(0.0, dtype=tf.float32)\n",
    "\n",
    "    # Iterate over batches of data for memory efficiency\n",
    "    for batch in dataset:\n",
    "        total_log_likelihood += calculate_probabilities_tf(\n",
    "            batch['tumor_ref'], batch['tumor_alt'], batch['normal_ref'], batch['normal_alt'],\n",
    "            batch['major'], batch['minor'], batch['totalCN'], TiN\n",
    "        )\n",
    "    return total_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>position</th>\n",
       "      <th>major</th>\n",
       "      <th>minor</th>\n",
       "      <th>totalCN</th>\n",
       "      <th>tumor_ref</th>\n",
       "      <th>tumor_alt</th>\n",
       "      <th>normal_ref</th>\n",
       "      <th>normal_alt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>13507816</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>13507817</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>13507818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>13507819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>13507820</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chr  position  major  minor  totalCN  tumor_ref  tumor_alt  normal_ref  \\\n",
       "0   21  13507816      1      1        2        103          0          22   \n",
       "1   21  13507817      1      1        2        103          0          22   \n",
       "2   21  13507818      1      1        2        102          0          21   \n",
       "3   21  13507819      1      1        2        102          0          21   \n",
       "4   21  13507820      1      1        2        101          0          21   \n",
       "\n",
       "   normal_alt  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your data with Pandas or Dask (for large files) and convert it to TensorFlow Dataset\n",
    "df = pd.read_csv(\"/rsrch8/home/genetics/tchu/TCGA_LUAD/estimate/head21.txt\", sep = \"\\t\", header = None, \n",
    "names=[\"chr\", \"position\", \"major\", \"minor\", \"totalCN\", \"tumor_ref\", \"tumor_alt\", \"normal_ref\", \"normal_alt\"],\n",
    "dtype={'chr': int, 'position': int, 'major': int, 'minor': int, 'totalCN': int, 'tumor_ref': int, 'tumor_alt': int, 'normal_ref': int, 'normal_alt': int},\n",
    "index_col=False)  # Load your large dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices({\n",
    "    'tumor_ref': tf.constant(df['tumor_ref'].values, dtype=tf.float32),\n",
    "    'tumor_alt': tf.constant(df['tumor_alt'].values, dtype=tf.float32),\n",
    "    'normal_ref': tf.constant(df['normal_ref'].values, dtype=tf.float32),\n",
    "    'normal_alt': tf.constant(df['normal_alt'].values, dtype=tf.float32),\n",
    "    'major': tf.constant(df['major'].values, dtype=tf.float32),\n",
    "    'minor': tf.constant(df['minor'].values, dtype=tf.float32),\n",
    "    'totalCN': tf.constant(df['totalCN'].values, dtype=tf.float32),\n",
    "})\n",
    "dataset = dataset.batch(1000)  # Adjust batch size based on available memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):  \u001b[38;5;66;03m# Number of optimization steps\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 12\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mtotal_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTiN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, [TiN])\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients, [TiN]))\n",
      "Cell \u001b[0;32mIn[17], line 33\u001b[0m, in \u001b[0;36mtotal_log_likelihood\u001b[0;34m(TiN, dataset)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Iterate over batches of data for memory efficiency\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m---> 33\u001b[0m     total_log_likelihood \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_probabilities_tf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtumor_ref\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtumor_alt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnormal_ref\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnormal_alt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmajor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mminor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotalCN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTiN\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_log_likelihood\n",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m, in \u001b[0;36mcalculate_probabilities_tf\u001b[0;34m(C_TR, C_TA, C_NR, C_NA, major, minor, totalCN, TiN)\u001b[0m\n\u001b[1;32m      4\u001b[0m C \u001b[38;5;241m=\u001b[39m C_T \u001b[38;5;241m+\u001b[39m C_N\n\u001b[1;32m      5\u001b[0m C_A \u001b[38;5;241m=\u001b[39m C_TA \u001b[38;5;241m+\u001b[39m C_NA\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m C \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m P_R_clonal \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mzeros_like(C_A, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:321\u001b[0m, in \u001b[0;36m_EagerTensorBase.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 321\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "TiN = tf.Variable(0.1, dtype=tf.float32)  # Starting guess for TiN\n",
    "TPR = 0.95  # Assumed true positive rate\n",
    "TNR = 0.95  # Assumed true negative rate\n",
    "TiT = 0.26   # Assumed tumor-in-tumor contamination\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Training loop to minimize negative log-likelihood\n",
    "for epoch in range(100):  # Number of optimization steps\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = total_log_likelihood(TiN, dataset)\n",
    "    gradients = tape.gradient(loss, [TiN])\n",
    "    optimizer.apply_gradients(zip(gradients, [TiN]))\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch}, Log Likelihood: {-loss.numpy()}, TiN: {TiN.numpy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
